{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e9cd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d9ada8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
       "0               7.4             0.700         0.00             1.9      0.076  \\\n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n",
       "0                    11.0                  34.0  0.99780  3.51       0.56  \\\n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = pd.read_csv('winequality-red.csv', sep=';')\n",
    "wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24bb8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n",
      "0      -0.528360          0.961877    -1.391472       -0.453218  -0.243707  \\\n",
      "1      -0.298547          1.967442    -1.391472        0.043416   0.223875   \n",
      "2      -0.298547          1.297065    -1.186070       -0.169427   0.096353   \n",
      "3       1.654856         -1.384443     1.484154       -0.453218  -0.264960   \n",
      "4      -0.528360          0.961877    -1.391472       -0.453218  -0.243707   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates   \n",
      "0            -0.466193             -0.379133  0.558274  1.288643  -0.579207  \\\n",
      "1             0.872638              0.624363  0.028261 -0.719933   0.128950   \n",
      "2            -0.083669              0.229047  0.134264 -0.331177  -0.048089   \n",
      "3             0.107592              0.411500  0.664277 -0.979104  -0.461180   \n",
      "4            -0.466193             -0.379133  0.558274  1.288643  -0.579207   \n",
      "\n",
      "    alcohol  \n",
      "0 -0.960246  \n",
      "1 -0.584777  \n",
      "2 -0.584777  \n",
      "3 -0.584777  \n",
      "4 -0.960246  \n"
     ]
    }
   ],
   "source": [
    "X = wine_data.drop(\"quality\", axis=1)\n",
    "y = wine_data['quality']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data using the scaler\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create a DataFrame with the standardized features\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "# Display the first few rows of the standardized features\n",
    "print(X_scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1778a0",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ad30ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train and y_train are already prepared from the previous steps\n",
    "\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the layers as specified\n",
    "model.add(Dense(11, input_dim=11, activation='relu'))\n",
    "model.add(Dense(11, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation=None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21750681",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4aca4bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "104/104 [==============================] - 1s 3ms/step - loss: 0.4678 - mean_squared_error: 0.4678 - mean_absolute_error: 0.5277 - val_loss: 0.3822 - val_mean_squared_error: 0.3822 - val_mean_absolute_error: 0.4924\n",
      "Epoch 2/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4577 - mean_squared_error: 0.4577 - mean_absolute_error: 0.5224 - val_loss: 0.3837 - val_mean_squared_error: 0.3837 - val_mean_absolute_error: 0.4914\n",
      "Epoch 3/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4468 - mean_squared_error: 0.4468 - mean_absolute_error: 0.5135 - val_loss: 0.3849 - val_mean_squared_error: 0.3849 - val_mean_absolute_error: 0.4929\n",
      "Epoch 4/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4408 - mean_squared_error: 0.4408 - mean_absolute_error: 0.5148 - val_loss: 0.3798 - val_mean_squared_error: 0.3798 - val_mean_absolute_error: 0.4877\n",
      "Epoch 5/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4372 - mean_squared_error: 0.4372 - mean_absolute_error: 0.5084 - val_loss: 0.3882 - val_mean_squared_error: 0.3882 - val_mean_absolute_error: 0.4838\n",
      "Epoch 6/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4354 - mean_squared_error: 0.4354 - mean_absolute_error: 0.5097 - val_loss: 0.3620 - val_mean_squared_error: 0.3620 - val_mean_absolute_error: 0.4783\n",
      "Epoch 7/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4274 - mean_squared_error: 0.4274 - mean_absolute_error: 0.5059 - val_loss: 0.3884 - val_mean_squared_error: 0.3884 - val_mean_absolute_error: 0.4984\n",
      "Epoch 8/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4283 - mean_squared_error: 0.4283 - mean_absolute_error: 0.5007 - val_loss: 0.3682 - val_mean_squared_error: 0.3682 - val_mean_absolute_error: 0.4756\n",
      "Epoch 9/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4221 - mean_squared_error: 0.4221 - mean_absolute_error: 0.4997 - val_loss: 0.3557 - val_mean_squared_error: 0.3557 - val_mean_absolute_error: 0.4774\n",
      "Epoch 10/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4255 - mean_squared_error: 0.4255 - mean_absolute_error: 0.5050 - val_loss: 0.3792 - val_mean_squared_error: 0.3792 - val_mean_absolute_error: 0.4813\n",
      "Epoch 11/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4243 - mean_squared_error: 0.4243 - mean_absolute_error: 0.5013 - val_loss: 0.3666 - val_mean_squared_error: 0.3666 - val_mean_absolute_error: 0.4748\n",
      "Epoch 12/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4252 - mean_squared_error: 0.4252 - mean_absolute_error: 0.5051 - val_loss: 0.3870 - val_mean_squared_error: 0.3870 - val_mean_absolute_error: 0.4833\n",
      "Epoch 13/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4174 - mean_squared_error: 0.4174 - mean_absolute_error: 0.4969 - val_loss: 0.3646 - val_mean_squared_error: 0.3646 - val_mean_absolute_error: 0.4744\n",
      "Epoch 14/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4143 - mean_squared_error: 0.4143 - mean_absolute_error: 0.4965 - val_loss: 0.3757 - val_mean_squared_error: 0.3757 - val_mean_absolute_error: 0.4886\n",
      "Epoch 15/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4137 - mean_squared_error: 0.4137 - mean_absolute_error: 0.4943 - val_loss: 0.3669 - val_mean_squared_error: 0.3669 - val_mean_absolute_error: 0.4757\n",
      "Epoch 16/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4088 - mean_squared_error: 0.4088 - mean_absolute_error: 0.4914 - val_loss: 0.3603 - val_mean_squared_error: 0.3603 - val_mean_absolute_error: 0.4802\n",
      "Epoch 17/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4102 - mean_squared_error: 0.4102 - mean_absolute_error: 0.4929 - val_loss: 0.3753 - val_mean_squared_error: 0.3753 - val_mean_absolute_error: 0.4898\n",
      "Epoch 18/25\n",
      "104/104 [==============================] - 0s 2ms/step - loss: 0.4115 - mean_squared_error: 0.4115 - mean_absolute_error: 0.4930 - val_loss: 0.3572 - val_mean_squared_error: 0.3572 - val_mean_absolute_error: 0.4765\n",
      "Epoch 19/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4052 - mean_squared_error: 0.4052 - mean_absolute_error: 0.4889 - val_loss: 0.3763 - val_mean_squared_error: 0.3763 - val_mean_absolute_error: 0.4847\n",
      "Epoch 20/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3991 - mean_squared_error: 0.3991 - mean_absolute_error: 0.4859 - val_loss: 0.3885 - val_mean_squared_error: 0.3885 - val_mean_absolute_error: 0.4820\n",
      "Epoch 21/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4035 - mean_squared_error: 0.4035 - mean_absolute_error: 0.4891 - val_loss: 0.3763 - val_mean_squared_error: 0.3763 - val_mean_absolute_error: 0.4804\n",
      "Epoch 22/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.4076 - mean_squared_error: 0.4076 - mean_absolute_error: 0.4911 - val_loss: 0.3757 - val_mean_squared_error: 0.3757 - val_mean_absolute_error: 0.4851\n",
      "Epoch 23/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3986 - mean_squared_error: 0.3986 - mean_absolute_error: 0.4869 - val_loss: 0.3803 - val_mean_squared_error: 0.3803 - val_mean_absolute_error: 0.4781\n",
      "Epoch 24/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3979 - mean_squared_error: 0.3979 - mean_absolute_error: 0.4855 - val_loss: 0.3796 - val_mean_squared_error: 0.3796 - val_mean_absolute_error: 0.4826\n",
      "Epoch 25/25\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 0.3973 - mean_squared_error: 0.3973 - mean_absolute_error: 0.4822 - val_loss: 0.3737 - val_mean_squared_error: 0.3737 - val_mean_absolute_error: 0.4800\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.3751 - mean_squared_error: 0.3751 - mean_absolute_error: 0.4975\n",
      "Mean Squared Error on Testing Set: 0.3751067817211151\n",
      "Mean Absolute Error on Testing Set: 0.4975319504737854\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "# Set aside 10% of the training data as validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "\n",
    "evaluation_results = model.evaluate(X_test, y_test)\n",
    "loss, mse, mae = evaluation_results\n",
    "print(f\"Mean Squared Error on Testing Set: {mse}\")\n",
    "print(f\"Mean Absolute Error on Testing Set: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40feda8",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8de2369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4347 - mean_squared_error: 0.4347 - mean_absolute_error: 0.5051 - val_loss: 0.4726 - val_mean_squared_error: 0.4726 - val_mean_absolute_error: 0.5284\n",
      "Epoch 2/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4391 - mean_squared_error: 0.4391 - mean_absolute_error: 0.5097 - val_loss: 0.4772 - val_mean_squared_error: 0.4772 - val_mean_absolute_error: 0.5496\n",
      "Epoch 3/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4372 - mean_squared_error: 0.4372 - mean_absolute_error: 0.5106 - val_loss: 0.4686 - val_mean_squared_error: 0.4686 - val_mean_absolute_error: 0.5404\n",
      "Epoch 4/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4330 - mean_squared_error: 0.4330 - mean_absolute_error: 0.5079 - val_loss: 0.4536 - val_mean_squared_error: 0.4536 - val_mean_absolute_error: 0.5300\n",
      "Epoch 5/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4316 - mean_squared_error: 0.4316 - mean_absolute_error: 0.5103 - val_loss: 0.4431 - val_mean_squared_error: 0.4431 - val_mean_absolute_error: 0.5106\n",
      "Epoch 6/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4133 - mean_squared_error: 0.4133 - mean_absolute_error: 0.4952 - val_loss: 0.4580 - val_mean_squared_error: 0.4580 - val_mean_absolute_error: 0.5077\n",
      "Epoch 7/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4106 - mean_squared_error: 0.4106 - mean_absolute_error: 0.4903 - val_loss: 0.4350 - val_mean_squared_error: 0.4350 - val_mean_absolute_error: 0.5049\n",
      "Epoch 8/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4080 - mean_squared_error: 0.4080 - mean_absolute_error: 0.4918 - val_loss: 0.4611 - val_mean_squared_error: 0.4611 - val_mean_absolute_error: 0.5286\n",
      "Epoch 9/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4044 - mean_squared_error: 0.4044 - mean_absolute_error: 0.4883 - val_loss: 0.4518 - val_mean_squared_error: 0.4518 - val_mean_absolute_error: 0.5097\n",
      "Epoch 10/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4031 - mean_squared_error: 0.4031 - mean_absolute_error: 0.4858 - val_loss: 0.4398 - val_mean_squared_error: 0.4398 - val_mean_absolute_error: 0.5087\n",
      "Epoch 11/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4015 - mean_squared_error: 0.4015 - mean_absolute_error: 0.4882 - val_loss: 0.4482 - val_mean_squared_error: 0.4482 - val_mean_absolute_error: 0.5125\n",
      "Epoch 12/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3946 - mean_squared_error: 0.3946 - mean_absolute_error: 0.4826 - val_loss: 0.4369 - val_mean_squared_error: 0.4369 - val_mean_absolute_error: 0.5089\n",
      "Epoch 13/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3953 - mean_squared_error: 0.3953 - mean_absolute_error: 0.4807 - val_loss: 0.4332 - val_mean_squared_error: 0.4332 - val_mean_absolute_error: 0.5027\n",
      "Epoch 14/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3967 - mean_squared_error: 0.3967 - mean_absolute_error: 0.4884 - val_loss: 0.4438 - val_mean_squared_error: 0.4438 - val_mean_absolute_error: 0.5086\n",
      "Epoch 15/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3928 - mean_squared_error: 0.3928 - mean_absolute_error: 0.4820 - val_loss: 0.4419 - val_mean_squared_error: 0.4419 - val_mean_absolute_error: 0.5044\n",
      "Epoch 16/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3886 - mean_squared_error: 0.3886 - mean_absolute_error: 0.4801 - val_loss: 0.4579 - val_mean_squared_error: 0.4579 - val_mean_absolute_error: 0.5181\n",
      "Epoch 17/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3872 - mean_squared_error: 0.3872 - mean_absolute_error: 0.4759 - val_loss: 0.4734 - val_mean_squared_error: 0.4734 - val_mean_absolute_error: 0.5117\n",
      "Epoch 18/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3835 - mean_squared_error: 0.3835 - mean_absolute_error: 0.4740 - val_loss: 0.4399 - val_mean_squared_error: 0.4399 - val_mean_absolute_error: 0.5071\n",
      "Epoch 19/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3796 - mean_squared_error: 0.3796 - mean_absolute_error: 0.4740 - val_loss: 0.4619 - val_mean_squared_error: 0.4619 - val_mean_absolute_error: 0.5252\n",
      "Epoch 20/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3843 - mean_squared_error: 0.3843 - mean_absolute_error: 0.4735 - val_loss: 0.4481 - val_mean_squared_error: 0.4481 - val_mean_absolute_error: 0.5148\n",
      "Epoch 21/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3864 - mean_squared_error: 0.3864 - mean_absolute_error: 0.4777 - val_loss: 0.4622 - val_mean_squared_error: 0.4622 - val_mean_absolute_error: 0.5166\n",
      "Epoch 22/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3851 - mean_squared_error: 0.3851 - mean_absolute_error: 0.4786 - val_loss: 0.4502 - val_mean_squared_error: 0.4502 - val_mean_absolute_error: 0.5159\n",
      "Epoch 23/25\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3778 - mean_squared_error: 0.3778 - mean_absolute_error: 0.4725 - val_loss: 0.4410 - val_mean_squared_error: 0.4410 - val_mean_absolute_error: 0.5119\n",
      "Epoch 24/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3720 - mean_squared_error: 0.3720 - mean_absolute_error: 0.4679 - val_loss: 0.4326 - val_mean_squared_error: 0.4326 - val_mean_absolute_error: 0.4996\n",
      "Epoch 25/25\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.3738 - mean_squared_error: 0.3738 - mean_absolute_error: 0.4744 - val_loss: 0.4325 - val_mean_squared_error: 0.4325 - val_mean_absolute_error: 0.4891\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.4325 - mean_squared_error: 0.4325 - mean_absolute_error: 0.4891\n",
      "\n",
      "Validation Results:\n",
      "Mean Squared Error on Validation Set: 0.4324972927570343\n",
      "Mean Absolute Error on Validation Set: 0.4890768229961395\n",
      "Final Loss (MSE) on Validation Set: 0.4324972927570343\n",
      "10/10 [==============================] - 0s 0s/step - loss: 0.4009 - mean_squared_error: 0.4009 - mean_absolute_error: 0.5094\n",
      "10/10 [==============================] - 0s 0s/step\n",
      "\n",
      "Test Results:\n",
      "Mean Squared Error on Test Set: 0.40085259079933167\n",
      "Mean Absolute Error on Test Set: 0.5094023942947388\n",
      "R^2 Score on Test Set: 0.3866120950419015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=25, batch_size=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# (f) Evaluate the model on the validation set\n",
    "validation_results = model.evaluate(X_val, y_val)\n",
    "val_loss, val_mse, val_mae = validation_results\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(f\"Mean Squared Error on Validation Set: {val_mse}\")\n",
    "print(f\"Mean Absolute Error on Validation Set: {val_mae}\")\n",
    "print(f\"Final Loss (MSE) on Validation Set: {val_loss}\")\n",
    "\n",
    "# (g) Assess the trained model’s performance on the test set\n",
    "test_results = model.evaluate(X_test, y_test)\n",
    "test_loss, test_mse, test_mae = test_results\n",
    "\n",
    "# Calculate R^2 score for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"Mean Squared Error on Test Set: {test_mse}\")\n",
    "print(f\"Mean Absolute Error on Test Set: {test_mae}\")\n",
    "print(f\"R^2 Score on Test Set: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a397e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
